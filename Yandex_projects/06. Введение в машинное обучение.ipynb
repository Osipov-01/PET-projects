{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Привет Иван! Меня зовут Марат, и я буду твоим ревьюером. Спешу сообщить что все ключевые этапы в работе выполнены,  с задачей тебе удалось справиться. По поводу обращения - в IT сфере принято общаться на «ты» :) Но, если привычней на «вы», дай знать. Как ревьюера моя задача помочь тебе в развитии, дав хорошие советы. Я внимательно посмотрю твой код, ознакомлюсь с твоими выводами и оставлю комментарии. Где то могу предложить небольшие исправление в коде, но ненавязчиво. Где потребуются уточнения, я оставлю много наводящих вопросов. Они помогут тебя с поиском верного решения.\n",
    "\n",
    "Все мои комментарии размечены по цветам, для лучшего восприятия. \n",
    "    \n",
    "<div class=\"alert alert-success\">Зеленым цветом и словом «Успех» отмечены особо удачные и элегантные решения, которыми ты можешь гордиться. </div>\n",
    "        \n",
    "<div class=\"alert alert-warning\">Желтым и значком словом «Совет», помечены решения у которых есть альтернативные решения, более оптимальные. Ты можешь найти их сразу и доработать проект, или отложить это на потом, для будущих проектах. Проект будет принят и без их доработки. </div>\n",
    "        \n",
    "<div class=\"alert alert-danger\"> Красным цветом и значком словом «Ошибка» помечу твои решения, на которые стоит обратить внимание прежде всего. После их доработки проект будет принят. </div>\n",
    "        \n",
    "Залог успеха - работа сообща, взаимное уважение и работа в диалоге. Поэтому, помечай свои ответные комментарии на мои реплики заметным цветом или курсивом, так мне будет легче их отслеживать. Пожалуйста, не изменяй и не удаляй мои комментарии. Все это поможет выполнить повторную проверку быстрей.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Рекомендация тарифов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В вашем распоряжении данные о поведении клиентов, которые уже перешли на эти тарифы (из проекта курса «Статистический анализ данных»). Нужно построить модель для задачи классификации, которая выберет подходящий тариф. Предобработка данных не понадобится — вы её уже сделали.\n",
    "\n",
    "Постройте модель с максимально большим значением *accuracy*. Чтобы сдать проект успешно, нужно довести долю правильных ответов по крайней мере до 0.75. Проверьте *accuracy* на тестовой выборке самостоятельно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Успех:\n",
    "\n",
    "\n",
    "Вступление в работу очень важно, так человек, который смотрит твой проект (и на работе в том числе) будет сразу введен в курс дела.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Откройте и изучите файл"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импорт нужных библиотек для работы с данными и чтение самих данных из файла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "df = pd.read_csv('/datasets/users_behavior.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Успех:\n",
    "\n",
    "Собираем все импорты в верхней части, чтобы легче было ориентироваться и добавлять новые по необходимости. \n",
    "\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Совет:     \n",
    "    \n",
    "\n",
    "\n",
    "- Иван, все-таки стоит импорт библиотек и выгрузку данных разнести в разные ячейки, так стилистически более правильно.\n",
    "\n",
    "\n",
    "- кстати есть рекомендации PEP-8 при написании кода, в том числе и для импортов. Если интересно можешь почитать [тут](https://pythonworld.ru/osnovy/pep-8-rukovodstvo-po-napisaniyu-koda-na-python.html), в будущем пригодится )  \n",
    "\n",
    "\n",
    "\n",
    "<div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выяснение основной информации о данных: какой столбец относится к определённому типу данных, что в них содержится."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.0</td>\n",
       "      <td>311.90</td>\n",
       "      <td>83.0</td>\n",
       "      <td>19915.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85.0</td>\n",
       "      <td>516.75</td>\n",
       "      <td>56.0</td>\n",
       "      <td>22696.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77.0</td>\n",
       "      <td>467.66</td>\n",
       "      <td>86.0</td>\n",
       "      <td>21060.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106.0</td>\n",
       "      <td>745.53</td>\n",
       "      <td>81.0</td>\n",
       "      <td>8437.39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66.0</td>\n",
       "      <td>418.74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14502.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   calls  minutes  messages   mb_used  is_ultra\n",
       "0   40.0   311.90      83.0  19915.42         0\n",
       "1   85.0   516.75      56.0  22696.96         0\n",
       "2   77.0   467.66      86.0  21060.45         0\n",
       "3  106.0   745.53      81.0   8437.39         1\n",
       "4   66.0   418.74       1.0  14502.75         0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.info())\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка данных на пустые значения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "calls       0\n",
       "minutes     0\n",
       "messages    0\n",
       "mb_used     0\n",
       "is_ultra    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изучение файла показало, что в действительности нет необходимости в предобработке данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Успех:\n",
    "\n",
    "👍 Данные изучены.\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "\n",
    "\n",
    "Совет: \n",
    "\n",
    "\n",
    "- Можно еще отдельно проверить датасет на сбалансированность классов в таргете. Это помогло бы решить бонусное задание сразу (Только не надо балансировать данные, это тема следующего проекта).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- Можно посмотреть корреляцию признаков. Знаешь что такое мультиколлинеарность, какие два типа проблем возникает, для каких моделей и какие варианты решения?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разбейте данные на выборки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Зададим для данных целевой признак (это тариф Смарт или Ультра), т.е. столбец 'is_ultra' - target, и признаки без целевого - features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df['is_ultra']\n",
    "features = df.drop(['is_ultra'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Разобьём данные на обучающие, валидационные и тестовые в соотношении 3:1:1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разбиение данных на обучающие (80% от исходных: в обучающие данные сами обучающие данные - 60% и валидационная - 20%) и тестовые (20%), т.е. в соотношении 4:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=.2, random_state=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разбиение обучающих данных на обучающие (75% или 60% от исходных) и валидационные (25% или 20% от исходных) в соотношении 3:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_valid, target_train, target_valid = train_test_split(features_train, target_train, test_size=.25, random_state=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Успех:\n",
    "\n",
    "Все правильно!\n",
    "\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "\n",
    "\n",
    "Совет: \n",
    "\n",
    "\n",
    "- Обрати внимание на аргумент stratify, он позволит сохранить изначальное распределение таргетов во всех новых датасетах.  Существующий дисбаланс никуда не денется, но в каждом датасете он будет одинаковым. [Почитать](https://pythonru.com/baza-znanij/sklearn-train-test-split) можно тут\n",
    "\n",
    "\n",
    "- После разбиения лучше перестраховаться и использовать .shape, для контроля за корректностью разбиения\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Исследуйте модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Исследуем модель \"дерево решений\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучающая выборка: 0.8117219917012448\n",
      "Валидационная выборка: 0.7651632970451011\n",
      "Время выполнения: 5.757570266723633 ms\n"
     ]
    }
   ],
   "source": [
    "best_model_tree = None\n",
    "best_result_tree_train = 0 \n",
    "best_result_tree_valid = 0\n",
    "best_time_tree = -1\n",
    "#best_result_tree_test = 0\n",
    "\n",
    "#Зададим гиперпараметр \"максимальная глубина дерева\" - depth, который будет меняться в цикле от 1 до 5 включительно\n",
    "for depth in range(1,6):\n",
    "    #Зададим модель и обучим её\n",
    "    time_start = time.time()\n",
    "    model = DecisionTreeClassifier(random_state=12345, max_depth = depth)\n",
    "    model.fit(features_train, target_train)\n",
    "    \n",
    "    #Найдем предсказания для всех выборок\n",
    "    predictions_train = model.predict(features_train)\n",
    "    predictions_valid = model.predict(features_valid)\n",
    "    #predictions_test = model.predict(features_test)\n",
    "    \n",
    "    #Определим качество предсказаний для валидационной выборки с помощью функции accuracy_score\n",
    "    result_valid = accuracy_score(target_valid, predictions_valid)\n",
    "    \n",
    "    #Выберем лучшее из всех\n",
    "    if result_valid > best_result_tree_valid:\n",
    "        best_model_tree = model\n",
    "        best_result_tree_train = accuracy_score(target_train, predictions_train)\n",
    "        best_result_tree_valid = result_valid\n",
    "        time_end = time.time()\n",
    "        best_time_tree = (time_end-time_start)* 10**3\n",
    "        #best_result_tree_test = accuracy_score(target_test, predictions_test)\n",
    "        \n",
    "print('Обучающая выборка:', best_result_tree_train)\n",
    "print('Валидационная выборка:', best_result_tree_valid)\n",
    "print(f'Время выполнения: {best_time_tree} ms')\n",
    "#print('Тестовая выборка:', best_result_tree_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "\n",
    "\n",
    "Ошибка ❌:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Пока не выберем лучшую модель на валидации, тестовой выборки для нас как будто бы не существует"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>Комментарий ревьюераV2</b></font>\n",
    "\n",
    "\n",
    "\n",
    "Успех 👍:\n",
    "\n",
    "\n",
    "\n",
    "Исправлено\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Успех:\n",
    " \n",
    "Работа выполнена в соответствии с критериями: \n",
    "\n",
    "\n",
    "\n",
    " - модель обучена на обучающем наборе\n",
    " - получена оценка качества на валидационном наборе\n",
    " - перебор гиперпараметров осуществляется в цикле\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "\n",
    "Совет: \n",
    "\n",
    "\n",
    "\n",
    "- Можно добавить график, хорошо оформленный график украсит проект. Тут на графике можно посмотреть как при изменении гиперпараметров меняется точность на train и validation датасете (для этого собираем наши метрики на валидации и train в списки, а затем по ним обычный plt.plot()) Такой способ используют чтобы лучше отследить переобучение, но для этого стоит взять пернебор по max_depth поглубже\n",
    "\n",
    "\n",
    "\n",
    "- tree_plot можно построить, с max_depth равной 3 или 4 (глубже уже будет громоздко) - глянуть как DT сплиты делает, будет понимание как модель принимает решения: какие признаки  использует, на каких значениях делает разбиение вправо - влево \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Исследуем модель \"случайный лес\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучающая выборка: 0.9797717842323651\n",
      "Валидационная выборка: 0.7884914463452566\n",
      "Время выполнения: 56.32209777832031 ms\n"
     ]
    }
   ],
   "source": [
    "best_model_forest = None\n",
    "best_result_forest_train = 0\n",
    "best_result_forest_valid = 0\n",
    "best_time_forest = -1\n",
    "#best_result_forest_test = 0\n",
    "\n",
    "#Зададим гиперпараметр \"количество деревьев в лесу\" - est, который будет меняться в цикле от 1 до 10 включительно\n",
    "for est in range(1,15):\n",
    "    #Зададим модель и обучим её\n",
    "    time_start = time.time()\n",
    "    model = RandomForestClassifier(random_state=12345, n_estimators=est)\n",
    "    model.fit(features_train, target_train)\n",
    "    \n",
    "    #Определим качество предсказаний для валидационной выборки с помощью функции model.score()\n",
    "    result = model.score(features_valid, target_valid)\n",
    "    \n",
    "    #Выберем лучшее из всех\n",
    "    if result > best_result_forest_valid:\n",
    "        best_model_forest = model\n",
    "        best_result_forest_train = model.score(features_train, target_train)\n",
    "        best_result_forest_valid = result\n",
    "        time_end = time.time()\n",
    "        best_time_forest = (time_end-time_start)* 10**3\n",
    "        #best_result_forest_test = model.score(features_test, target_test)\n",
    "        \n",
    "print('Обучающая выборка:', best_result_forest_train)\n",
    "print('Валидационная выборка:', best_result_forest_valid)\n",
    "print(f'Время выполнения: {best_time_forest} ms')\n",
    "\n",
    "#print('Тестовая выборка:', best_result_forest_test)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Успех:\n",
    "\n",
    "\n",
    "Верно. \n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Совет:\n",
    "\n",
    "\n",
    "- Иван, можно было сделать похитрее, RF одна из лучших моделей в классическом machine-learning, поэтому можно было добавить перебор 2 гиперпараметров в двойном цикле, в результата метрика качества вырастет. \n",
    " \n",
    "\n",
    "- Когда что то долго крутиться, можно использовать  %%time - ставишь на самый вверх ячейки с кодом, время выполнения которого хочешь замерить, может не знаешь.  Быстрее не станет, но все будут видеть стоит ли ждать не отходя от ПК или можно сходить чаек поставить )) \n",
    "    \n",
    "    Или tqdm, это ещё лучше, потому что он показывает интерактивно, на каком этапе расчетов мы находимся\n",
    "\n",
    "    \n",
    "    from tqdm import tqdm\n",
    "\n",
    "\n",
    "    for n_estimators in tqdm(range(3,58)):\n",
    "\n",
    "        ..........\n",
    "\n",
    "    \n",
    "И будет красиво )   \n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Комментарий:** вместо %%time решил использовать библиотеку time c функцией time, т.е. time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Устар.* Можно заметить, что качество тестовых выборок в обоих моделях одинаковое."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "\n",
    "\n",
    "Ошибка ❌:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Забыли о тестовый выборке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Исследуем модель \"логистическая регрессия\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучающая выборка: 0.7422199170124482\n",
      "Валидационная выборка: 0.7371695178849145\n",
      "Время выполнения: 24.571895599365234 ms\n"
     ]
    }
   ],
   "source": [
    "#import warnings\n",
    "#warnings.filterwarnings('ignore')\n",
    "#Поднял import выше\n",
    "\n",
    "best_model_log = None\n",
    "best_result_log_train = 0\n",
    "best_result_log_valid = 0\n",
    "best_time_log = -1\n",
    "#best_result_log_test = 0\n",
    "\n",
    "#Зададим гиперпараметр \"количество итераций\" - iter, который будет меняться в цикле от 1 до 100 включительно\n",
    "for iter in range(1,101):\n",
    "    #Зададим модель и обучим её\n",
    "    time_start = time.time()\n",
    "    model = LogisticRegression(random_state=12345, solver='lbfgs', max_iter=iter)\n",
    "    model.fit(features_train, target_train)\n",
    "    \n",
    "    #Определим качество предсказаний для валидационной выборки с помощью функции model.score()\n",
    "    result = model.score(features_valid, target_valid)\n",
    "    \n",
    "    #Выберем лучшее из всех\n",
    "    if result > best_result_log_valid:\n",
    "        best_model_log = model\n",
    "        best_result_log_train = model.score(features_train, target_train)\n",
    "        best_result_log_valid = result\n",
    "        time_end = time.time()\n",
    "        best_time_log = (time_end-time_start)* 10**3\n",
    "        #best_result_log_test = model.score(features_test, target_test)\n",
    "        \n",
    "print('Обучающая выборка:', best_result_log_train)\n",
    "print('Валидационная выборка:', best_result_log_valid)\n",
    "print(f'Время выполнения: {best_time_log} ms')\n",
    "#print('Тестовая выборка:', best_result_log_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "\n",
    "\n",
    "Ошибка ❌:\n",
    "\n",
    "\n",
    "\n",
    "Не забываем поднимать импорты наверх\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Исходя из 3 моделей (\"дерево решений\", \"случайный лес\", \"логистическая регрессия\") лучше всего показала 2-я модель, у которой лучше всех качество предсказаний по валидационной выборке, но, помимо этого, у неё также лучшее качество и в тестовой выборке наравне с \"деревом решений\". Следовательно, модель \"случайный лес\" более подходящая для предсказаний выбора пользователем тарифа (\"Смарт\" или \"Ультра\") на основе предложенных данных. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Успех:\n",
    "\n",
    "\n",
    "Все верно, RF лучший. \n",
    "\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "\n",
    "Совет: \n",
    "\n",
    "Если есть желание можешь ответить на вопросики ))    \n",
    "\n",
    "\n",
    "\n",
    "- Как назвать ситуацию, когда на валидации при увеличении глубины дерева (модель DT), метрика качества стала снижаться? Как по твоему в это же время вела себя эта же метрика на train?\n",
    "\n",
    "\n",
    "- Насколько знаю вы еще под капот моделям не заглядывали, но может знаешь почему обычно RF показывает более высокие результаты из выбранных?\n",
    "\n",
    "\n",
    "- Мы решаем задачу классификации (а еще есть задача регрессии), а в названии модели с помощью которой мы решаем задачу \"классификации\" (Логистическая регрессия) есть слово \"регрессия\".  Нет ли тут парадокса? )\n",
    "    \n",
    "\n",
    "- Почему логистическая регрессия показывать на много более худшие результаты?  \n",
    "\n",
    "\n",
    "</div>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ответы на вопросы:**\n",
    "2. По-моему, модель \"случайный лес\" - смесь \"деревьев решений\", т.е. эта модель лучше последней\n",
    "3. Модель логистической регрессии нужна для прогнозирования результатов 0/1, да/нет или правда/ложь, целевой признак \"is_ultra\" как и является таковым.\n",
    "\n",
    "В остальном пока затрудняюсь ответить"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>Комментарий ревьюераV2</b></font>\n",
    "\n",
    "\n",
    "Успех:\n",
    "\n",
    "\n",
    "Дополню чуть\n",
    "\n",
    "1. Переобучение. На train точность растет вплоть до 100%. \n",
    "    \n",
    "    \n",
    "2. Да, в RF обучается несколько деревьев, а решение принимается путем голосования. Каждое дерево в RF учится на своем датасете (используется техника бутстрап), таким образом достигается \"независимость\" этих самых деревьев, в итоге ошибка разброса снижается.\n",
    "\n",
    "    \n",
    "3. \"Регрессия\", потому что внутри нее скалярное произведение (как и в линейной регрессии), дающее на выходе вещественное число (от + бесконечности до - бесконечности), на это число вешают сигмойду, логарифм и получают значение от 0 до 1 (вероятность класса).   \n",
    "    \n",
    "    \n",
    "4. Логистическая регрессия плоха (и хороша с другой стороны) тем что это линейный классификатор: обьекты на классы разделяем гиперплоскостью (прямой если на плоскости), а в данном датасете видимо более сложные, нелинейные связи между признаками и таргетом.   А RF с DT с этим справляются. На других данных  LR могла оказаться лучше, например потому что RF не может экстраполировать. \n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверьте модель на тестовой выборке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Устар.* Данный шаг был сделан в разделе выше, причём на всех моделях."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В предыдущем пункте выяснено, что модель RF является лучшей. Проверим эту модель на тестовой выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Анализ модели RF на тестовой выборке\n",
      "Случайный лес: качество - 0.7869362363919129, время - 5.665063858032227 ms\n"
     ]
    }
   ],
   "source": [
    "#Случайный лес\n",
    "start = time.time()\n",
    "result_forest_test = best_model_forest.score(features_test, target_test)\n",
    "end = time.time()\n",
    "time_forest = (end-start)*10**3\n",
    "\n",
    "print('Анализ модели RF на тестовой выборке')\n",
    "print(f'Случайный лес: качество - {result_forest_test}, время - {time_forest} ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данная модель показала, что она может верно предсказывать выбор клиентом нужного для себя тарифа с вероятностью 78.7%, что является неплохим результатом."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>Комментарий ревьюераV3</b></font>\n",
    "\n",
    "Успех:\n",
    "\n",
    "Если студент получил на тесте accuraсy  выше 0,78, это считается отличным результатом.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<font size=\"5\"><b>Комментарий ревьюераV2</b></font>\n",
    "\n",
    "\n",
    "\n",
    "Ошибка ❌:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Тестируем только лучшую модель\n",
    "Это делается для того, чтобы мы даже незначительным образом не \"подгонялись\" под тестовую выборку. Ведь на train модели обучаются, по валидиации подгоняются гиперпараметры. Эти данные модели \"знают\". А test (out-of-sample) это уже моделирование прогноза на реальных данных и ситуации когда у нас есть уже лучшая модель (в рельности у нас же не может быть несоклько прогнозов, что то в любом случаи надо выбирать). Вот поэтому такая двухуровневая проверка на подгонку. Кроме того использование мноих моделей с разными гиперпараметрами это тоже подгонка, поэтому выбирая одну и тестируя только ее, мы тем самым боремся с подгонкой через использование многих-многих моделей, когда результат хорош не потому что мы данные почистили хорошо, моделировали правильно итд итп, а потому что из многих моделей хоть какая то случайно \"сыграет\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что по качеству одинаково хорошо показали себя две модели: \"дерево решений\", \"случайный лес\", но и последняя третья модель (\"логистическая регрессия\") тоже далеко не ушла, она чуть похуже; по скорости лучше всего вышла третья модель, чуть помедленнее сработало \"дерево решений\", в роли \"черепахи\" выступила модель \"случайный лес\", но эта разница во времени не заметна для человеческого глаза, учитывая, что 1 ms (\"миллисекунда\") = 0.001 s (\"секунда\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-danger\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Ошибка:\n",
    "\n",
    "\n",
    "А должны сделать это тут\n",
    "\n",
    "Иван, о логике использования датасетов:\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "1. На train мы обучаем\n",
    "2. По валидации смотрим на результаты обучения (следим чтобы не было переобучения и/или делаем подбор гиперпараметров).  И выбираем лучшую модель. \n",
    "3. Тестовая (out-of_sample) у нас для финальной проверки, когда определена лучшая по валидации модель с конкретными гиперпараметрами. \n",
    "    \n",
    "    \n",
    "    \n",
    " [Вот](https://towardsdatascience.com/why-do-we-need-a-validation-set-in-addition-to-training-and-test-sets-5cf4a65550e0   ) тут можно дополнительно почитать.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (бонус) Проверьте модели на адекватность"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Дерево решений: accuracy - 0.7651632970451011, f1_score - 0.5113268608414241\n",
      "Случайный лес: accuracy - 0.7884914463452566, f1_score - 0.6023391812865497\n",
      "Логистическая регрессия: accuracy - 0.7371695178849145, f1_score - 0.32128514056224905\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "f1_score_tree = f1_score(target_valid, best_model_tree.predict(features_valid))\n",
    "f1_score_forest = f1_score(target_valid, best_model_forest.predict(features_valid))\n",
    "f1_score_log = f1_score(target_valid, best_model_log.predict(features_valid))\n",
    "\n",
    "print(f'Дерево решений: accuracy - {best_result_tree_valid}, f1_score - {f1_score_tree}')\n",
    "print(f'Случайный лес: accuracy - {best_result_forest_valid}, f1_score - {f1_score_forest}')\n",
    "print(F'Логистическая регрессия: accuracy - {best_result_log_valid}, f1_score - {f1_score_log}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<font size=\"5\"><b>Комментарий ревьюераV2</b></font>\n",
    "\n",
    "\n",
    "\n",
    "Ошибка ❌:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Импорт поднимаем наверх"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Исходя из этого, можно считать, что модель \"случайный лес\" лучше показала себя на адекватность, т.к. у неё больше всех значение f1_score. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Совет:\n",
    "\n",
    "\n",
    "Иван, тобой решено проверить модель на адекватность \"подгрузив\" несколько других метрик качества. Да, в этом резон есть, например нам важно было качество предсказания какого-то одного класса, тогда да, мы бы проверяли на метриках, которые учитывают это и получили бы более адекватные оценки.   \n",
    "\n",
    "Но в данном случаи мы проверяем модель на адекватность сравнивая ее с наивным прогнозом (простой \"угадалкой\" или прогноз одного и того же класса). Не забудь у нас дисбаланс классов в таргете. \n",
    "\n",
    "\n",
    "При проверке на адекватность модели, рекомендую ознакомиться с [Dummy Models](https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html), это удобная обертка для константных моделей\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<font size=\"5\"><b>Комментарий ревьюераV2</b></font>\n",
    "\n",
    "Совет:\n",
    "\n",
    "\n",
    "Тут логика такая - у нас есть данные и мы видим что доля нулей в таргете около 69%, это значит что мы не проводя никакого анализа, моделирования итп итд, можем постоянно предсказывать 0 и получить точность около 69%. Вот эту accuracy в 69% мы и должны побить, иначе окажется что наша модель не лучше наивного прогноза самого частого класса.\n",
    "      \n",
    "    \n",
    "С   DummyClassifier это выглядит  так:\n",
    "    \n",
    "    DummyClassifier(strategy='most_frequent', random_state=1)  \n",
    "задаем константную модель, которая будет предсказывать по most_frequent - самый частый класс\n",
    "    \n",
    "    .fit(features_train, target_train)\n",
    "тут модель смотри на самый частый класс в  target_train - типо \"обучение\"\n",
    "    \n",
    "    .predict(features_test)\n",
    "    .score(features_test, target_test)\n",
    "проогнозирует везде самый частый класс в features_test и считает score\n",
    "    \n",
    "Получаем тот же результат: acc около 69%.    \n",
    "\n",
    "\n",
    "\n",
    "Сравниваем с accuracy нашей модели и делаем вывод\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чек-лист готовности проекта"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поставьте 'x' в выполненных пунктах. Далее нажмите Shift+Enter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] Jupyter Notebook открыт\n",
    "- [x] Весь код исполняется без ошибок\n",
    "- [x] Ячейки с кодом расположены в порядке исполнения\n",
    "- [x] Выполнено задание 1: данные загружены и изучены\n",
    "- [x] Выполнено задание 2: данные разбиты на три выборки\n",
    "- [x] Выполнено задание 3: проведено исследование моделей\n",
    "    - [x] Рассмотрено больше одной модели\n",
    "    - [x] Рассмотрено хотя бы 3 значения гипепараметров для какой-нибудь модели\n",
    "    - [x] Написаны выводы по результатам исследования\n",
    "- [x] Выполнено задание 3: Проведено тестирование\n",
    "- [x] Удалось достичь accuracy не меньше 0.75 *(за исключением модели \"логистическая регрессия\" - приближенно 0.74)*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Общий вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Итоговый вывод:** В данном проекте был изучены данные клиентов оператора мобильной связи \"Мегалайн\", где выяснилось, что не требуется предобработка данных.\n",
    "\n",
    "Данные были разбиты по столбцам на целевой признак (ответы) - столбец 'is_ultra' и признаки(вопросы) - все остальные столбцы, по строкам на обучающие, валидационные и тестовые данные в соотношении 3:1:1 (= 60%:20%:20%)\n",
    "\n",
    "Далее были исследованы три модели машинного обучения, связанные с классификацией данных: \"дерево решений\", \"случайный лес\", \"логистическая регрессия\". Лучше всего из 3 моделей показала результат на качество и вменяемость - модель \"случайный лес\".\n",
    "\n",
    "Таким образом, оператору мобильной связи \"Мегалайн\" следует выбрать модель предсказаний \"случайный лес\" для построения системы, способной проанализировать поведение клиентов и предложить пользователям новый тариф: «Смарт» или «Ультра»."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Успех:\n",
    "\n",
    "\n",
    "Иван, здорово что в конце расписаны все этапы работы. Это важно потому что когда проект захочет посмотреть будущий работодатель (или начальник), у него может не быть времени на подробный разбор кода. Вероятнее всего он бегло просмотрит код, а из общего вывода захочет получить представление о всей работе.\n",
    "\n",
    "\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-info\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Иван, у тебя старательно выполненная работа, все четко, осмысленно. Выводы присутствуют, с комментированием кода тоже никаких проблем нет, твоих объяснений достаточно для понимания коллегами хода твоих мыслей. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Я оставил небольшие советы и вопросики (если есть время и желание можешь воспользоваться/ответить): \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- обрати внимание на проверку сбалансированность классов в таргете в разделе EDA\n",
    "- использовать stratify\n",
    "- добавить график метрики    \n",
    "- как можно улучшить результаты \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "Обязательное к исправлению:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- импорты собираем в одном месте, так будет удобней и тебе и тем коллегам кто будет работать с твоим кодом    \n",
    "\n",
    "\n",
    "    \n",
    "- стоит переделать бонусное задание с учётом моего комментария (по желанию, это все таки бонусное)\n",
    " \n",
    "    \n",
    "    \n",
    "- нарушена логика использования датасетов   -  на тестовой выборке тестируем только лучшую модель \n",
    "\n",
    "    \n",
    "    \n",
    "Жду исправлений, для принятия проекта. Если какие то вопросы, то сразу спрашивай ) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-info\">\n",
    "<font size=\"5\"><b>Комментарий ревьюераV2</b></font>\n",
    "\n",
    "Спасибо за работу!    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "Что осталось из красного:\n",
    "\n",
    " \n",
    "\n",
    "    \n",
    "- Финальное тестирование проводим только на лучшей модели\n",
    "    \n",
    "    \n",
    "- Импорты поднимаем наверх    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-info\">\n",
    "<font size=\"5\"><b>Комментарий ревьюераV3</b></font>\n",
    "\n",
    "Спасибо за работу!    \n",
    "\n",
    "    \n",
    "Красное исправлено.\n",
    "  \n",
    "Отличная работа Иван. Желаю успехов в дальнейшей учебе!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 525,
    "start_time": "2023-02-18T20:54:28.485Z"
   },
   {
    "duration": 173,
    "start_time": "2023-02-18T20:54:49.941Z"
   },
   {
    "duration": 24,
    "start_time": "2023-02-18T20:55:47.491Z"
   },
   {
    "duration": 19,
    "start_time": "2023-02-18T20:57:36.641Z"
   },
   {
    "duration": 7,
    "start_time": "2023-02-18T20:57:56.609Z"
   },
   {
    "duration": 7,
    "start_time": "2023-02-18T21:14:18.347Z"
   },
   {
    "duration": 646,
    "start_time": "2023-02-18T21:14:25.341Z"
   },
   {
    "duration": 17,
    "start_time": "2023-02-18T21:14:26.971Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-18T21:14:29.267Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-18T21:14:30.923Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-18T21:15:23.852Z"
   },
   {
    "duration": 6,
    "start_time": "2023-02-18T21:15:46.824Z"
   },
   {
    "duration": 109,
    "start_time": "2023-02-18T21:21:17.487Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-18T21:34:44.339Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-18T21:36:07.215Z"
   },
   {
    "duration": 7,
    "start_time": "2023-02-18T21:37:08.462Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-18T21:37:29.343Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-18T21:37:31.308Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-18T21:37:35.425Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-18T22:49:29.169Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-18T22:53:10.796Z"
   },
   {
    "duration": 42,
    "start_time": "2023-02-18T22:53:13.657Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-18T22:54:52.613Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-18T22:55:25.867Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-18T22:55:28.304Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-18T22:55:30.609Z"
   },
   {
    "duration": 7,
    "start_time": "2023-02-18T22:55:36.443Z"
   },
   {
    "duration": 1364,
    "start_time": "2023-02-19T21:25:06.021Z"
   },
   {
    "duration": 44,
    "start_time": "2023-02-19T21:25:09.994Z"
   },
   {
    "duration": 6,
    "start_time": "2023-02-19T21:33:29.168Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-19T21:33:31.463Z"
   },
   {
    "duration": 6,
    "start_time": "2023-02-19T21:33:33.656Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-19T21:33:35.853Z"
   },
   {
    "duration": 73,
    "start_time": "2023-02-19T21:58:18.874Z"
   },
   {
    "duration": 21,
    "start_time": "2023-02-19T21:58:21.919Z"
   },
   {
    "duration": 9,
    "start_time": "2023-02-19T21:58:25.285Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-19T21:58:27.387Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-19T21:58:29.083Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-19T21:58:30.866Z"
   },
   {
    "duration": 28,
    "start_time": "2023-02-19T22:23:10.116Z"
   },
   {
    "duration": 20,
    "start_time": "2023-02-19T22:23:15.783Z"
   },
   {
    "duration": 6,
    "start_time": "2023-02-19T22:23:18.088Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-19T22:23:20.012Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-19T22:23:21.958Z"
   },
   {
    "duration": 6,
    "start_time": "2023-02-19T22:23:23.656Z"
   },
   {
    "duration": 13,
    "start_time": "2023-02-19T22:24:40.845Z"
   },
   {
    "duration": 7,
    "start_time": "2023-02-19T22:28:56.093Z"
   },
   {
    "duration": 7,
    "start_time": "2023-02-19T22:32:43.184Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-19T22:34:32.544Z"
   },
   {
    "duration": 6,
    "start_time": "2023-02-19T22:34:40.196Z"
   },
   {
    "duration": 45,
    "start_time": "2023-02-19T23:02:29.009Z"
   },
   {
    "duration": 1161,
    "start_time": "2023-02-20T08:58:23.389Z"
   },
   {
    "duration": 40,
    "start_time": "2023-02-20T08:58:27.733Z"
   },
   {
    "duration": 7,
    "start_time": "2023-02-20T08:58:30.148Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-20T08:58:32.714Z"
   },
   {
    "duration": 6,
    "start_time": "2023-02-20T08:58:35.382Z"
   },
   {
    "duration": 6,
    "start_time": "2023-02-20T08:58:37.290Z"
   },
   {
    "duration": 47,
    "start_time": "2023-02-20T08:58:39.458Z"
   },
   {
    "duration": 45,
    "start_time": "2023-02-20T09:01:11.077Z"
   },
   {
    "duration": 46,
    "start_time": "2023-02-20T09:06:10.354Z"
   },
   {
    "duration": 50,
    "start_time": "2023-02-20T09:08:54.067Z"
   },
   {
    "duration": 53,
    "start_time": "2023-02-20T09:10:51.610Z"
   },
   {
    "duration": 44,
    "start_time": "2023-02-20T09:12:16.174Z"
   },
   {
    "duration": 439,
    "start_time": "2023-02-20T09:15:41.198Z"
   },
   {
    "duration": 1710,
    "start_time": "2023-02-20T09:38:26.359Z"
   },
   {
    "duration": 1654,
    "start_time": "2023-02-20T09:39:23.563Z"
   },
   {
    "duration": 1608,
    "start_time": "2023-02-20T09:41:16.914Z"
   },
   {
    "duration": 2535,
    "start_time": "2023-02-20T09:42:19.253Z"
   },
   {
    "duration": 1534,
    "start_time": "2023-02-20T09:42:37.269Z"
   },
   {
    "duration": 60,
    "start_time": "2023-02-20T09:52:03.862Z"
   },
   {
    "duration": 53,
    "start_time": "2023-02-20T09:52:11.253Z"
   },
   {
    "duration": 44,
    "start_time": "2023-02-20T09:52:15.630Z"
   },
   {
    "duration": 121,
    "start_time": "2023-02-20T11:27:07.351Z"
   },
   {
    "duration": 15,
    "start_time": "2023-02-20T11:28:07.565Z"
   },
   {
    "duration": 2025,
    "start_time": "2023-02-20T12:00:19.377Z"
   },
   {
    "duration": 25,
    "start_time": "2023-02-20T12:00:21.404Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-20T12:00:21.431Z"
   },
   {
    "duration": 13,
    "start_time": "2023-02-20T12:00:21.438Z"
   },
   {
    "duration": 10,
    "start_time": "2023-02-20T12:00:21.453Z"
   },
   {
    "duration": 9,
    "start_time": "2023-02-20T12:00:21.465Z"
   },
   {
    "duration": 62,
    "start_time": "2023-02-20T12:00:21.476Z"
   },
   {
    "duration": 301,
    "start_time": "2023-02-20T12:00:21.540Z"
   },
   {
    "duration": 1877,
    "start_time": "2023-02-20T12:00:21.843Z"
   },
   {
    "duration": 14,
    "start_time": "2023-02-20T12:00:23.723Z"
   },
   {
    "duration": 1138,
    "start_time": "2023-02-23T14:49:22.667Z"
   },
   {
    "duration": 28,
    "start_time": "2023-02-23T14:49:26.343Z"
   },
   {
    "duration": 7,
    "start_time": "2023-02-23T14:49:30.393Z"
   },
   {
    "duration": 7,
    "start_time": "2023-02-23T14:51:56.648Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-23T14:51:59.747Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-23T14:52:01.861Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-23T14:52:03.212Z"
   },
   {
    "duration": 114,
    "start_time": "2023-02-23T14:52:07.464Z"
   },
   {
    "duration": 61,
    "start_time": "2023-02-23T14:52:21.709Z"
   },
   {
    "duration": 280,
    "start_time": "2023-02-23T14:52:37.862Z"
   },
   {
    "duration": 2002,
    "start_time": "2023-02-23T14:54:02.457Z"
   },
   {
    "duration": 87,
    "start_time": "2023-02-23T14:57:57.485Z"
   },
   {
    "duration": 486,
    "start_time": "2023-02-23T14:58:11.700Z"
   },
   {
    "duration": 284,
    "start_time": "2023-02-23T14:58:21.811Z"
   },
   {
    "duration": 19276,
    "start_time": "2023-02-23T14:58:28.333Z"
   },
   {
    "duration": 904,
    "start_time": "2023-02-23T14:58:56.511Z"
   },
   {
    "duration": 477,
    "start_time": "2023-02-23T14:59:07.341Z"
   },
   {
    "duration": 26,
    "start_time": "2023-02-23T15:00:48.652Z"
   },
   {
    "duration": 71,
    "start_time": "2023-02-23T15:05:58.552Z"
   },
   {
    "duration": 86,
    "start_time": "2023-02-23T15:07:18.078Z"
   },
   {
    "duration": 88,
    "start_time": "2023-02-23T15:07:25.092Z"
   },
   {
    "duration": 80,
    "start_time": "2023-02-23T15:07:26.731Z"
   },
   {
    "duration": 77,
    "start_time": "2023-02-23T15:07:28.477Z"
   },
   {
    "duration": 103,
    "start_time": "2023-02-23T15:07:30.318Z"
   },
   {
    "duration": 74,
    "start_time": "2023-02-23T15:07:32.253Z"
   },
   {
    "duration": 75,
    "start_time": "2023-02-23T15:07:33.817Z"
   },
   {
    "duration": 75,
    "start_time": "2023-02-23T15:07:35.482Z"
   },
   {
    "duration": 84,
    "start_time": "2023-02-23T15:07:37.071Z"
   },
   {
    "duration": 80,
    "start_time": "2023-02-23T15:07:38.667Z"
   },
   {
    "duration": 114,
    "start_time": "2023-02-23T15:07:39.986Z"
   },
   {
    "duration": 110,
    "start_time": "2023-02-23T15:07:41.395Z"
   },
   {
    "duration": 78,
    "start_time": "2023-02-23T15:07:43.371Z"
   },
   {
    "duration": 511,
    "start_time": "2023-02-23T15:09:21.230Z"
   },
   {
    "duration": 509,
    "start_time": "2023-02-23T15:09:41.002Z"
   },
   {
    "duration": 476,
    "start_time": "2023-02-23T15:09:44.400Z"
   },
   {
    "duration": 510,
    "start_time": "2023-02-23T15:09:47.343Z"
   },
   {
    "duration": 487,
    "start_time": "2023-02-23T15:09:49.754Z"
   },
   {
    "duration": 277,
    "start_time": "2023-02-23T15:10:01.026Z"
   },
   {
    "duration": 267,
    "start_time": "2023-02-23T15:10:02.761Z"
   },
   {
    "duration": 20009,
    "start_time": "2023-02-23T15:10:09.866Z"
   },
   {
    "duration": 479,
    "start_time": "2023-02-23T15:10:38.529Z"
   },
   {
    "duration": 1926,
    "start_time": "2023-02-23T15:11:28.827Z"
   },
   {
    "duration": 2058,
    "start_time": "2023-02-23T15:11:33.925Z"
   },
   {
    "duration": 12,
    "start_time": "2023-02-23T16:46:09.918Z"
   },
   {
    "duration": 68,
    "start_time": "2023-02-23T16:46:38.117Z"
   },
   {
    "duration": 478,
    "start_time": "2023-02-23T16:46:40.670Z"
   },
   {
    "duration": 2006,
    "start_time": "2023-02-23T16:46:42.891Z"
   },
   {
    "duration": 20,
    "start_time": "2023-02-23T16:46:50.132Z"
   },
   {
    "duration": 235,
    "start_time": "2023-02-23T16:47:04.667Z"
   },
   {
    "duration": 13,
    "start_time": "2023-02-23T16:47:10.996Z"
   },
   {
    "duration": 854,
    "start_time": "2023-02-23T16:47:40.026Z"
   },
   {
    "duration": 60,
    "start_time": "2023-02-23T16:47:50.205Z"
   },
   {
    "duration": 828,
    "start_time": "2023-02-23T16:47:54.562Z"
   },
   {
    "duration": 1970,
    "start_time": "2023-02-23T16:47:56.820Z"
   },
   {
    "duration": 13,
    "start_time": "2023-02-23T16:48:00.183Z"
   },
   {
    "duration": 16,
    "start_time": "2023-02-23T16:52:25.134Z"
   },
   {
    "duration": 19,
    "start_time": "2023-02-23T16:53:49.820Z"
   },
   {
    "duration": 15,
    "start_time": "2023-02-23T16:53:52.353Z"
   },
   {
    "duration": 21,
    "start_time": "2023-02-23T16:53:55.834Z"
   },
   {
    "duration": 17,
    "start_time": "2023-02-23T16:53:58.052Z"
   },
   {
    "duration": 19,
    "start_time": "2023-02-23T16:53:59.528Z"
   },
   {
    "duration": 17,
    "start_time": "2023-02-23T16:54:01.210Z"
   },
   {
    "duration": 19,
    "start_time": "2023-02-23T16:54:02.305Z"
   },
   {
    "duration": 18,
    "start_time": "2023-02-23T16:54:03.312Z"
   },
   {
    "duration": 16,
    "start_time": "2023-02-23T16:54:04.256Z"
   },
   {
    "duration": 14,
    "start_time": "2023-02-23T16:54:05.287Z"
   },
   {
    "duration": 15,
    "start_time": "2023-02-23T16:54:06.205Z"
   },
   {
    "duration": 14,
    "start_time": "2023-02-23T16:54:07.456Z"
   },
   {
    "duration": 14,
    "start_time": "2023-02-23T16:54:10.775Z"
   },
   {
    "duration": 14,
    "start_time": "2023-02-23T16:54:15.571Z"
   },
   {
    "duration": 17,
    "start_time": "2023-02-23T16:54:17.835Z"
   },
   {
    "duration": 38,
    "start_time": "2023-02-23T16:54:44.418Z"
   },
   {
    "duration": 838,
    "start_time": "2023-02-23T16:54:47.708Z"
   },
   {
    "duration": 1949,
    "start_time": "2023-02-23T16:54:49.738Z"
   },
   {
    "duration": 14,
    "start_time": "2023-02-23T16:54:54.008Z"
   },
   {
    "duration": 19931,
    "start_time": "2023-02-23T16:55:18.873Z"
   },
   {
    "duration": 23,
    "start_time": "2023-02-23T16:58:10.160Z"
   },
   {
    "duration": 30,
    "start_time": "2023-02-23T16:58:12.927Z"
   },
   {
    "duration": 27,
    "start_time": "2023-02-23T16:58:14.806Z"
   },
   {
    "duration": 39,
    "start_time": "2023-02-23T16:58:16.352Z"
   },
   {
    "duration": 30,
    "start_time": "2023-02-23T16:58:18.247Z"
   },
   {
    "duration": 26,
    "start_time": "2023-02-23T16:58:19.785Z"
   },
   {
    "duration": 25,
    "start_time": "2023-02-23T16:58:21.283Z"
   },
   {
    "duration": 492,
    "start_time": "2023-02-23T16:58:37.376Z"
   },
   {
    "duration": 16,
    "start_time": "2023-02-23T16:58:41.416Z"
   },
   {
    "duration": 13,
    "start_time": "2023-02-23T16:58:44.866Z"
   },
   {
    "duration": 13,
    "start_time": "2023-02-23T16:58:47.160Z"
   },
   {
    "duration": 15,
    "start_time": "2023-02-23T16:58:49.220Z"
   },
   {
    "duration": 15,
    "start_time": "2023-02-23T16:58:49.968Z"
   },
   {
    "duration": 13,
    "start_time": "2023-02-23T16:58:51.271Z"
   },
   {
    "duration": 14,
    "start_time": "2023-02-23T16:58:52.216Z"
   },
   {
    "duration": 15,
    "start_time": "2023-02-23T16:58:53.354Z"
   },
   {
    "duration": 16,
    "start_time": "2023-02-23T16:58:54.199Z"
   },
   {
    "duration": 13,
    "start_time": "2023-02-23T16:58:55.067Z"
   },
   {
    "duration": 15,
    "start_time": "2023-02-23T16:58:56.161Z"
   },
   {
    "duration": 14,
    "start_time": "2023-02-23T16:58:57.912Z"
   },
   {
    "duration": 14,
    "start_time": "2023-02-23T16:58:58.904Z"
   },
   {
    "duration": 14,
    "start_time": "2023-02-23T16:59:00.073Z"
   },
   {
    "duration": 18,
    "start_time": "2023-02-23T16:59:19.479Z"
   },
   {
    "duration": 20,
    "start_time": "2023-02-23T16:59:26.952Z"
   },
   {
    "duration": 14,
    "start_time": "2023-02-23T16:59:53.597Z"
   },
   {
    "duration": 471,
    "start_time": "2023-02-23T16:59:57.551Z"
   },
   {
    "duration": 13,
    "start_time": "2023-02-23T17:00:05.327Z"
   },
   {
    "duration": 26,
    "start_time": "2023-02-23T17:42:28.519Z"
   },
   {
    "duration": 18,
    "start_time": "2023-02-23T17:42:31.581Z"
   },
   {
    "duration": 6,
    "start_time": "2023-02-23T17:42:34.106Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-23T17:42:36.702Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-23T17:42:39.165Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-23T17:42:39.982Z"
   },
   {
    "duration": 52,
    "start_time": "2023-02-23T17:42:42.549Z"
   },
   {
    "duration": 636,
    "start_time": "2023-02-23T17:42:45.758Z"
   },
   {
    "duration": 2045,
    "start_time": "2023-02-23T17:42:49.924Z"
   },
   {
    "duration": 15,
    "start_time": "2023-02-23T17:42:54.677Z"
   },
   {
    "duration": 16,
    "start_time": "2023-02-23T17:42:57.534Z"
   },
   {
    "duration": 1232,
    "start_time": "2023-02-28T14:52:34.314Z"
   },
   {
    "duration": 24,
    "start_time": "2023-02-28T14:52:38.557Z"
   },
   {
    "duration": 7,
    "start_time": "2023-02-28T14:52:40.777Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-28T14:52:43.232Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-28T14:52:45.180Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-28T14:52:48.865Z"
   },
   {
    "duration": 37,
    "start_time": "2023-02-28T14:52:53.337Z"
   },
   {
    "duration": 512,
    "start_time": "2023-02-28T14:52:56.955Z"
   },
   {
    "duration": 2185,
    "start_time": "2023-02-28T14:53:00.273Z"
   },
   {
    "duration": 10,
    "start_time": "2023-02-28T14:53:05.362Z"
   },
   {
    "duration": 19,
    "start_time": "2023-02-28T14:53:09.245Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
